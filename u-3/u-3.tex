\documentclass[ngerman,a4paper]{scrartcl}
\usepackage{relsize}
\usepackage{fullpage}
\usepackage[german]{babel}
\usepackage{graphicx}

%Compiler
\usepackage{ifxetex}
\usepackage{ifluatex}
\ifxetex
  \usepackage{fontspec,xunicode}
  \catcode`\ß=13
  \defß{\ss}
\else\ifluatex
  \usepackage{fontspec,xunicode}
\else
  \usepackage[utf8]{inputenc}
\fi\fi
% /Compiler

\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{listings}
\lstset{frame=single}

\newcommand{\norm}[1]{\left|\!\left|#1\right|\! \right|}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}

\begin{document}
{\sffamily
  \hfill
  Computerorientierete Mathematik SS 2013\hfill
  FU Berlin\\[8pt]
  \noindent {\Huge Übung 3}\hfill Carlos Martín Nieto, Tran Tu\hrule \bigskip
}

\section*{1}

\paragraph{a)}

Die Funktionswerte oszillieren, was man mit $[-1,1]$ nicht sieht. Beim
erhöhen der Ordnung der Interpolation kann man sehen, dass die Werte
an den "`Grenzen"' sehr stark schwingen und je mehr Stützstellen wir
wählen, desto stärker tun sie es. Es gibt ein Unterschied zwischen der
Interpolationsmethoden. Die klassische Interpolation bleibt stabiler.

\paragraph{b)}

Der Plot von $w(x)$ über $[-1,1]$ bleibt bei Null, während der Plot
über $[-3,3]$ wackelt. Dies ist auch, was bei \textbf{a)} passiert,
$[-1,1]$ ist stabiler als $[-3,3]$.

\section*{2}
\paragraph{a)}
Es gilt, dass
\[
\sum^n_{k=0} f(k) = \sum^n_{k=0} f(n-k) \quad (*)
\]

und
\[
\int\limits^b_a f(t) dt = \int\limits^b_a f(a+b-t) dt \quad (**)
\]

Jetzt berechnen wir die Relation zwischen $x_k$ und $x_{n-k}$

\begin{align*}
  x_K &= a+hk\quad h = \frac{b-a}{n}\\
  x_{n-k} &= a+h(n-k) = a+(b-a) - kh = b-kh\\
  x_k + x_{n-k} &= a+b\\
  x_k &= a+b-x_{n-k}
\end{align*}

Aus
\[
\int\limits^b_a f(t) dt = \sum^n_{k=0} \lambda_k f(x_k) + R
\]

können wir es auch so schreiben:

\begin{align*}
  \int\limits^b_a f(a+b-t) dt &= \sum^n_{k=0} \lambda_k f(a+b-x_k)
  + R\\
  \int\limits^b_a f(t) dt &= \sum^n_{k=0} \lambda_{n-k} f(a+b-x_{n-k})
  + R
\end{align*}

Aus $(*)$ und $(**)$ und $x_k = a+b-x_{n-k}$ ist dies auch gleich
\[
\int\limits^b_a f(t) dt =\sum^n_{k=0} \lambda_{n-k} f(x_k) + R
\]

Und somit muss $\lambda_k$ den gleichen Wert haben als $\lambda_{n-k}$

\hfill$\square$
\section*{3}

Wir definieren $N_{n+1}(x) = (x - x_0)\dots(x-x_n)$ und $R$ als
überbleibendes Polynom vom Grad $n$. Wir können das Polynom $p \in
P_{n+1}$ so definieren

\[
p = a_{n+1} \cdot N_{n+1} + R
\]

Der Fehler berechnen wir mit

\begin{align*}
  E_n(p) &= |I(p) - I_n(p)|\\
  \intertext{Aus der Exaktheit von Grad $n$ folgt}
  &= a_{n+1}\cdot\left[I\left(N_{n+1}\right) -
    I_n\left(N_{n+1}\right)\right]
\end{align*}

$N_{n+1}$ ist punktsymmetrisch zu $\frac{a+b}{2}$, und daher ist
$I(N_{n+1}) = 0$.\\

$I_n(N_{n+1})$ ist $(x_0 - x_n)\sum^n_{k=1} \lambda_k N_{n+1}(x_n)$
und wird auch Null da die Summe mit den Nullstellen des
Newton-Polynoms arbeitet.

\end{document}
