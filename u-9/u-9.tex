\documentclass[ngerman,a4paper]{scrartcl}
\usepackage{relsize}
\usepackage{fullpage}
\usepackage[german]{babel}
\usepackage{graphicx}
\usepackage{cancel}

%Compiler
\usepackage{ifxetex}
\usepackage{ifluatex}
\ifxetex
  \usepackage{fontspec,xunicode}
  \catcode`\ß=13
  \defß{\ss}
\else\ifluatex
  \usepackage{fontspec,xunicode}
\else
  \usepackage[utf8]{inputenc}
\fi\fi
% /Compiler

\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{listings}
\lstset{frame=single}

\newcommand{\norm}[1]{\left|\!\left|#1\right|\! \right|}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}

\begin{document}
{\sffamily
  \hfill
  CoMa-II SS 2013\hfill
  FU Berlin\\[8pt]
  \noindent {\Huge Übung 9}\hfill Carlos Martín Nieto, Tran Tu\hrule \bigskip
}

\section*{1}

Mit der Tayloreihe

\[
x(t_k + \tau) = x(t_k) + x'(t_k)\tau + \frac{1}{2} x''(\xi) \tau^2
\]

und Konsistenzfehler-Formel

\[
\varepsilon(t_k,\tau) = x(t_k + \tau) - x(t_{k-1}) - \tau(\lambda x(t_k) + f(t_k))
\]

ergibt sich eine Konsistenzordung von:

\begin{align*}
\varepsilon(t_k,\tau) &= x(t_k + \tau) - x(t_{k-1}) - \tau(\lambda x(t_k) + f(t_k))\\
&= \cancel(x(t_k)) + x'(t_k)\tau + \frac{1}{2}x''(\xi)\tau^2 - \cancel{x(t_k)} -\tau(\lambda x(t_k) + f(t_k))\\
&= \tau(\cancel{x(t_k)} - \cancel{\lambda x(t_k) + f(t_k)}) + x(t_k) - x(t_{k-1}) + \frac{1}{2}x''(\xi)\tau^2\\
&=  x(t_k) - x(t_{k-1}) + \frac{1}{2}x''(\xi)\tau^2
\end{align*}

Daraus ergbit sicht

\begin{align*}
   &\max_{t\in (0, T]} |x(t_k) - x(t_{k-1}) + \frac{1}{2}x''(\xi)\tau^2| = \\
   &  |x(T)| - |x(T-\tau)| + \frac{1}{2}\max_{t\in (0, T]} |x''(\xi)|\tau^2
\end{align*}

Mit $C = |x(T)| - |x(T-\tau)| + \frac{1}{2}\norm{x''}_\infty$ haben
wir die Form $C\tau^{p+1}$ mit $p=1$.

\section*{2}

Von der letzten Übung wissen wir

\[
x_{k+1} = x_k + \underbrace{\frac{\lambda \tau}{2} (x_k + x_{k+1})}_{\int\limits^{t+\tau}_t \lambda x \, dt}
\]

Daher gilt

\[
\varepsilon(t_k, \tau) = x_{k+1} - x_k - \frac{\lambda\tau}{2} (x_k + x_{k+1}) \quad (1)
\]

Da


\begin{align*}
  x'(t) &= \lambda x(t) \implies \frac{dx}{dt} \lambda x \quad t_k +
  \tau t_{k+1}\\
  &\implies \int^{t_{k+1}}_{t_k} \frac{dx}{dt} dt = \int^{t_{k+1}}_{t_k} \! \lambda x\, dt\\
  &\implies x(t_{k+1}) - x(t_k) = \lambda \int^{t_{k+1}}_{t_k} \! x\, dt \quad (*)\\
  \intertext{Trapezregel}\\
  \lambda \int^{t_{k+1}}_{t_k} \! x\, dt &= \frac{\lambda\tau}{2} [x(t_{k+1}) + x(t_k)]
\end{align*}

Zuzüglich der Fehlerdarstellung der Trapezregel $\frac{\tau^3}{12}x''(\xi)$


\begin{align*}
  (*) \quad x(t_{k+1}) - x(t_k) &= \frac{\lambda\tau}{2}[x(t_{k+1}) +
  x(t_k)] + \frac{\tau^3}{12} x''(\xi)\\
  x(t_k + 1) = x(t_k) + \frac{\lambda\tau}{2} [x(t_{k+1}) +
  x(t_k)] + \frac{\tau^3}{12} x''(\xi)\\
\end{align*}

Wir setzen (2) in (1) ein

\begin{align*}
  \varepsilon(t_k, \tau) &= \cancel{x_k} + \cancel{\frac{\lambda\tau}{2} (x_{k+1} + x_k)}
  + \frac{\tau^3}{12} x''(\xi) - \cancel{x_k} - \cancel{\frac{\lambda\tau}{2} (x_{k} + x_{k+1})}\\
  &= \frac{\tau^3}{12} x''(\xi)
\end{align*}

Daraus folgt

\[
\max_{k=0,\dots,n-1} |\varepsilon(t_k, \tau)| \leq \frac{1}{12} \max_{t \in (0, T]} | x''(t)| \tau^3
\]

$\implies$ $p=2$ mit $C = \frac{1}{12} ||x''||_\infty$

\section*{3}

Zuerst subtraieren wir $\lambda E$, wobei $E$ die Einheitsmatrix ist

\[
A - \lambda E =
\begin{pmatrix}
  0-\lambda & 2 & -1\\
  2 & -1-\lambda & 1\\
  2 & -1 & 3-\lambda
\end{pmatrix}
\]

Dann berechnen wir die Determinante durch Sarrus

\begin{align*}
  \det(A-\lambda E) &= (0-\lambda)(-1-\lambda)(3-\lambda) + 4 + 2 - (2\lambda + 2 + \lambda + 12 - 4\lambda)\\
  &= -\lambda^3 + 2\lambda^2 + 4\lambda - 8\\
  &= -(\lambda - 2)(\lambda - 2)(\lambda+2)
\end{align*}

Die Nullstellen davon (Eigenwerte) sind also $\lambda_1 = 2$, $\lambda_2 =
2$, $\lambda_3 = -2$

Um die Eigenvektoren zu berechnen, setzen wir sie in das
Gleichungssystem aus $A-\lambda E$. Zuerst $\lambda_{1,2} = 2$.

\begin{align*}
  &\begin{pmatrix}
    -2 & 2 & -1\\
    2 & -3 & 1\\
    2 & -1 & 1\\
  \end{pmatrix} \cdot x =
  \begin{pmatrix}
    0\\0\\0
  \end{pmatrix} \implies   \begin{pmatrix}
    -2 & 2 & -1 & 0\\
    2 & -3 & 1 & 0\\
    2 & -1 & 1 & 0\\
  \end{pmatrix}\\
  &\implies \begin{pmatrix}
    -2 & 2 & -1 & 0\\
    0 & -1 & 0 & 0\\
    0 & 1 & 0 & 0\\
  \end{pmatrix}
  \implies \begin{pmatrix}
    2 & 0 & 1 & 0\\
    0 & 1 & 0 & 0\\
    0 & 0 & 0 & 0\\
  \end{pmatrix}
\end{align*}

Was uns $x_2 = -2x_1$ gibt. Der Eigenvektor ist also $1, 0, -2)^T$.

Analog für $\lambda_3 = -2$.

\begin{align*}
    &\begin{pmatrix}
    2 & 2 & -1\\
    2 & 1 & 1\\
    2 & -1 & 5\\
  \end{pmatrix} \cdot x =
  \begin{pmatrix}
    0\\0\\0
  \end{pmatrix} \implies
  \begin{pmatrix}
    2 & 0 & 3 & 0\\
    0 & 1 & -2 & 0\\
    0 & 0 & 0 & 0
  \end{pmatrix}
\end{align*}

Was uns $x_1 = \frac{-3}{2}x_3$, $x_2 = 2x_1$. Der Eigenvektor ist also $(3, -4, -2)^T$

\end{document}
